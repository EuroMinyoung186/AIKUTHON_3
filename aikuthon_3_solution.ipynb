{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6363696,"sourceType":"datasetVersion","datasetId":3665976},{"sourceId":6364410,"sourceType":"datasetVersion","datasetId":3666505}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\n\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\nimport random\nimport os\nfrom tqdm import tqdm, trange\nfrom pprint import pprint","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1gd1QF20SiR","outputId":"97bb4233-9254-4317-8e99-21b5184d896c","execution":{"iopub.status.busy":"2024-04-18T09:04:10.397387Z","iopub.execute_input":"2024-04-18T09:04:10.397693Z","iopub.status.idle":"2024-04-18T09:04:14.674867Z","shell.execute_reply.started":"2024-04-18T09:04:10.397666Z","shell.execute_reply":"2024-04-18T09:04:14.673019Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"## Seed를 설정합니다.\n## https://m.blog.naver.com/vail131/222306329719 참조\n\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)","metadata":{"id":"ph67PK1D8AkI","execution":{"iopub.status.busy":"2024-04-18T09:04:44.633761Z","iopub.execute_input":"2024-04-18T09:04:44.634793Z","iopub.status.idle":"2024-04-18T09:04:44.644118Z","shell.execute_reply.started":"2024-04-18T09:04:44.634754Z","shell.execute_reply":"2024-04-18T09:04:44.643182Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## genre에 저장되어있는 숫자와 실제 장르 명의 대응관계입니다.\n\n## 모델을 어떻게 학습시켰는가에 따라, test datset에 존재하는 장르만 사용하도록\n## id2label, label2 id, num_classes를 변경해도 괜찮습니다.\n\n## e.g.\nid2label = {'발라드': 0, '록/메탈': 1, '댄스': 2, 'POP': 4,'R&B/Soul': 5, '랩/힙합': 7, '성인가요/트로트': 16}\nlabel2id = {value: key for key, value in id2label.items()}\nnum_classes = 7\n\n\n# id2label = {\n#     '발라드': 0, '록/메탈': 1, '댄스': 2, '포크/블루스': 3,'POP': 4,'R&B/Soul': 5, '-': 6,\n#     '랩/힙합': 7, '국내영화': 8, 'CCM': 9, '국내CCM': 10, '클래식': 11,'오페라/성악': 12, '국외영화': 13,\n#     '국내드라마': 14, '인디음악': 15, '성인가요/트로트': 16, '일렉트로니카': 17, '뉴에이지': 18,\n#     '키즈': 19, '창작동요': 20, '크로스오버': 21, '재즈': 22, '보컬재즈': 23, '애시드/퓨전/팝': 24,\n#     '월드뮤직': 25, '애니메이션/웹툰': 26, '만화': 27, '게임': 28, 'J-POP': 29, '중국음악': 30,\n#     '샹송/프렌치팝': 31, '컨트리': 32, '국내뮤지컬': 33, '블루스': 34, '국외CCM': 35,\n#     '포크': 36, '국외뮤지컬': 37, '가톨릭': 38, '국외드라마': 39, '브라질': 40, '뮤직테라피': 41,\n#     '보사노바': 42, '라틴': 43, '국악': 44, '국악가요': 45, '찬송가': 46, '영어동요': 47, '워십': 48,\n#     '불교': 49,'자장가': 50, '민요': 51}\n# label2id = {value: key for key, value in id2label.items()}\n# num_classes = len(id2label)\n\nprint(f\"num_classes: {num_classes}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8FPGY4x8UvJ","outputId":"902661d9-245c-4a0e-f67a-c5c261d128be","execution":{"iopub.status.busy":"2024-04-18T09:04:46.502243Z","iopub.execute_input":"2024-04-18T09:04:46.502586Z","iopub.status.idle":"2024-04-18T09:04:46.510332Z","shell.execute_reply.started":"2024-04-18T09:04:46.502561Z","shell.execute_reply":"2024-04-18T09:04:46.509362Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"num_classes: 7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. DataLoader & Path 설정","metadata":{"id":"kgQapWje-Fq-"}},{"cell_type":"code","source":"## test df를 불러옵니다.\ntest_path = '/kaggle/input/dataset/test.csv'\ntest_ = pd.read_csv(test_path)\n\ntrain_path = '/kaggle/input/dataset/train.csv'\ntrain_ = pd.read_csv(train_path)","metadata":{"id":"9vo88d218XHd","execution":{"iopub.status.busy":"2024-04-18T09:04:48.792670Z","iopub.execute_input":"2024-04-18T09:04:48.793034Z","iopub.status.idle":"2024-04-18T09:04:54.454338Z","shell.execute_reply.started":"2024-04-18T09:04:48.793003Z","shell.execute_reply":"2024-04-18T09:04:54.453545Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"## 첫 열의 이름을 'id'로 바꾸어줍니다.\ntest_df = test_.rename(columns=({'Unnamed: 0':'id'}))\nprint(test_df.shape)\ntest_df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"Nw1I_KF8_A4Q","outputId":"78884086-19d7-4d2a-f2d8-70a25f4fecbc","execution":{"iopub.status.busy":"2024-04-18T09:04:56.621317Z","iopub.execute_input":"2024-04-18T09:04:56.621719Z","iopub.status.idle":"2024-04-18T09:04:56.646333Z","shell.execute_reply.started":"2024-04-18T09:04:56.621686Z","shell.execute_reply":"2024-04-18T09:04:56.645331Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(10500, 7)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"         id             song_name  adults             artist    album_id  \\\n0  33093058       TYPE (feat. 기린)       0                슬리피  '10524862'   \n1   2388517             Paparazzi       0          Lady Gaga    '741056'   \n2  31013021                   위하여       0                조항조  '10157289'   \n3  34801938         붉어지기도 전에 떨어진…       0                박완규  '10899614'   \n4   4061054  Strawberry Bubblegum       0  Justin Timberlake   '2178525'   \n\n         date                                             lyrics  \n0  2020.11.27  괜히 생각나 네 말이\\n너와 가고 싶어 저 멀리\\n너도 그래\\n아주 그래 BABE\\...  \n1  2009.12.09  We are the crowd\\nWe're cuh coming out\\nGot my...  \n2  2018.04.12  쓰디쓴 술잔을 비우고 또 비워봐도 \\n내 가슴속 너만은 비울 수가 없구나 \\n안녕이...  \n3  2022.02.25  갈망하는 노을처럼\\n한 줌의 재가 되어 고운\\n홍조 오르기도 전에 떨어져\\n그 자리...  \n4  2013.03.15  Hey pretty lady\\nThis goes out to you\\nI know ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>song_name</th>\n      <th>adults</th>\n      <th>artist</th>\n      <th>album_id</th>\n      <th>date</th>\n      <th>lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33093058</td>\n      <td>TYPE (feat. 기린)</td>\n      <td>0</td>\n      <td>슬리피</td>\n      <td>'10524862'</td>\n      <td>2020.11.27</td>\n      <td>괜히 생각나 네 말이\\n너와 가고 싶어 저 멀리\\n너도 그래\\n아주 그래 BABE\\...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2388517</td>\n      <td>Paparazzi</td>\n      <td>0</td>\n      <td>Lady Gaga</td>\n      <td>'741056'</td>\n      <td>2009.12.09</td>\n      <td>We are the crowd\\nWe're cuh coming out\\nGot my...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31013021</td>\n      <td>위하여</td>\n      <td>0</td>\n      <td>조항조</td>\n      <td>'10157289'</td>\n      <td>2018.04.12</td>\n      <td>쓰디쓴 술잔을 비우고 또 비워봐도 \\n내 가슴속 너만은 비울 수가 없구나 \\n안녕이...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34801938</td>\n      <td>붉어지기도 전에 떨어진…</td>\n      <td>0</td>\n      <td>박완규</td>\n      <td>'10899614'</td>\n      <td>2022.02.25</td>\n      <td>갈망하는 노을처럼\\n한 줌의 재가 되어 고운\\n홍조 오르기도 전에 떨어져\\n그 자리...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4061054</td>\n      <td>Strawberry Bubblegum</td>\n      <td>0</td>\n      <td>Justin Timberlake</td>\n      <td>'2178525'</td>\n      <td>2013.03.15</td>\n      <td>Hey pretty lady\\nThis goes out to you\\nI know ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df = train_.rename(columns=({'Unnamed: 0':'id'}))\n\nprint(train_df.shape)\ntrain_df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"-C7uCdpk_N7o","outputId":"55b52dc0-c7c2-4594-d500-27089d1ffb8b","execution":{"iopub.status.busy":"2024-04-18T09:04:59.133664Z","iopub.execute_input":"2024-04-18T09:04:59.134176Z","iopub.status.idle":"2024-04-18T09:04:59.160316Z","shell.execute_reply.started":"2024-04-18T09:04:59.134122Z","shell.execute_reply":"2024-04-18T09:04:59.159202Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(135792, 8)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     id   song_name  adults artist album_id        date genre  \\\n0  2395         긴 잠       0    INO   '1869'  2001.03.16     0   \n1  2396    Alcatraz       0    INO   '1869'  2001.03.16     1   \n2  2397          해요       0    INO   '1869'  2001.03.16     0   \n3  2398      투비(鬪悲)       0    INO   '1869'  2001.03.16     0   \n4  2399  Dying Love       0    INO   '1869'  2001.03.16  0, 1   \n\n                                              lyrics  \n0  잠을 깨는 것이 싫었어\\n눈 뜨면 또 하루\\n니 곁을 살테니\\n오직 내꿈 속엔 넌 ...  \n1  이젠 널 가둬놓겠어\\n나의 품에\\n조금은 낯설겠지만\\n편해질꺼야\\n두려운 내 맘 때...  \n2  그녀와 나는요 그땐 참 어렸어요\\n많이 사랑했고 때론 많이 다퉜었죠\\n지금 생각하면...  \n3  예전처럼 다시 처음으로\\n서로 몰랐던 때로 돌아가\\n쉽진 않지만\\n부탁이야 잊어줘\\...  \n4  천번을 하늘 앞에 다짐해왔어\\n무참히 날 버렸던\\n너를 지우겠다고\\n하지만 그리움이...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>song_name</th>\n      <th>adults</th>\n      <th>artist</th>\n      <th>album_id</th>\n      <th>date</th>\n      <th>genre</th>\n      <th>lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2395</td>\n      <td>긴 잠</td>\n      <td>0</td>\n      <td>INO</td>\n      <td>'1869'</td>\n      <td>2001.03.16</td>\n      <td>0</td>\n      <td>잠을 깨는 것이 싫었어\\n눈 뜨면 또 하루\\n니 곁을 살테니\\n오직 내꿈 속엔 넌 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2396</td>\n      <td>Alcatraz</td>\n      <td>0</td>\n      <td>INO</td>\n      <td>'1869'</td>\n      <td>2001.03.16</td>\n      <td>1</td>\n      <td>이젠 널 가둬놓겠어\\n나의 품에\\n조금은 낯설겠지만\\n편해질꺼야\\n두려운 내 맘 때...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2397</td>\n      <td>해요</td>\n      <td>0</td>\n      <td>INO</td>\n      <td>'1869'</td>\n      <td>2001.03.16</td>\n      <td>0</td>\n      <td>그녀와 나는요 그땐 참 어렸어요\\n많이 사랑했고 때론 많이 다퉜었죠\\n지금 생각하면...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2398</td>\n      <td>투비(鬪悲)</td>\n      <td>0</td>\n      <td>INO</td>\n      <td>'1869'</td>\n      <td>2001.03.16</td>\n      <td>0</td>\n      <td>예전처럼 다시 처음으로\\n서로 몰랐던 때로 돌아가\\n쉽진 않지만\\n부탁이야 잊어줘\\...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2399</td>\n      <td>Dying Love</td>\n      <td>0</td>\n      <td>INO</td>\n      <td>'1869'</td>\n      <td>2001.03.16</td>\n      <td>0, 1</td>\n      <td>천번을 하늘 앞에 다짐해왔어\\n무참히 날 버렸던\\n너를 지우겠다고\\n하지만 그리움이...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import re\n\ndef has_korean(text):\n    # 정규식 패턴을 사용하여 한글 문자가 있는지 판별\n    korean_pattern = re.compile('[ㄱ-ㅎㅏ-ㅣ가-힣]')\n    return bool(korean_pattern.search(text))","metadata":{"id":"RNoq5iBrT7dO","execution":{"iopub.status.busy":"2024-04-18T09:05:01.736861Z","iopub.execute_input":"2024-04-18T09:05:01.737252Z","iopub.status.idle":"2024-04-18T09:05:01.742459Z","shell.execute_reply.started":"2024-04-18T09:05:01.737222Z","shell.execute_reply":"2024-04-18T09:05:01.741310Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def find_kor(data):\n  has_kor = []\n  for song_name, artist, lyrics in zip(train_df['song_name'],train_df['artist'],train_df['lyrics']):\n    has_kor.append(has_korean(lyrics+song_name+artist))\n\n  return has_kor","metadata":{"id":"Ws0wRnBvSUGW","execution":{"iopub.status.busy":"2024-04-18T09:05:03.598318Z","iopub.execute_input":"2024-04-18T09:05:03.598670Z","iopub.status.idle":"2024-04-18T09:05:03.604270Z","shell.execute_reply.started":"2024-04-18T09:05:03.598640Z","shell.execute_reply":"2024-04-18T09:05:03.603323Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def genre_fix(data):\n  extracted = data[(data['genre'] == '0') | (data['genre'] == '1') | (data['genre'] == '2') | (data['genre'] == '4') \\\n          | (data['genre'] == '5') | (data['genre'] == '7') | (data['genre'] == '16')]\n\n  return extracted","metadata":{"id":"vcmRv8iWa228","execution":{"iopub.status.busy":"2024-04-18T09:05:05.616785Z","iopub.execute_input":"2024-04-18T09:05:05.617455Z","iopub.status.idle":"2024-04-18T09:05:05.622617Z","shell.execute_reply.started":"2024-04-18T09:05:05.617421Z","shell.execute_reply":"2024-04-18T09:05:05.621649Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df['has_kor'] = pd.DataFrame(find_kor(train_df))\ntest_df['has_kor'] = pd.DataFrame(find_kor(test_df))","metadata":{"id":"PoratebsTOEF","execution":{"iopub.status.busy":"2024-04-18T09:05:07.468702Z","iopub.execute_input":"2024-04-18T09:05:07.469091Z","iopub.status.idle":"2024-04-18T09:05:10.293402Z","shell.execute_reply.started":"2024-04-18T09:05:07.469058Z","shell.execute_reply":"2024-04-18T09:05:10.292448Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df = genre_fix(train_df)","metadata":{"id":"N_woINVNcXaY","execution":{"iopub.status.busy":"2024-04-18T09:05:13.265297Z","iopub.execute_input":"2024-04-18T09:05:13.266083Z","iopub.status.idle":"2024-04-18T09:05:13.422229Z","shell.execute_reply.started":"2024-04-18T09:05:13.266051Z","shell.execute_reply":"2024-04-18T09:05:13.421417Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.astype({'genre':'int'})","metadata":{"id":"vAtV7gz9GA-W","execution":{"iopub.status.busy":"2024-04-18T09:05:15.625283Z","iopub.execute_input":"2024-04-18T09:05:15.625711Z","iopub.status.idle":"2024-04-18T09:05:15.659598Z","shell.execute_reply.started":"2024-04-18T09:05:15.625673Z","shell.execute_reply":"2024-04-18T09:05:15.658680Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df['genre'] == 4, 'genre'] = 3\ntrain_df.loc[train_df['genre'] == 5, 'genre'] = 4\ntrain_df.loc[train_df['genre'] == 7, 'genre'] = 5\ntrain_df.loc[train_df['genre'] == 16, 'genre'] = 6","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:05:17.537680Z","iopub.execute_input":"2024-04-18T09:05:17.538753Z","iopub.status.idle":"2024-04-18T09:05:17.543841Z","shell.execute_reply.started":"2024-04-18T09:05:17.538718Z","shell.execute_reply":"2024-04-18T09:05:17.542978Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['has_kor']==False]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"tfy3DCB3c9NE","outputId":"d27f25cd-8296-446f-a350-0dc0a67d0811","execution":{"iopub.status.busy":"2024-04-18T09:05:25.662676Z","iopub.execute_input":"2024-04-18T09:05:25.663131Z","iopub.status.idle":"2024-04-18T09:05:25.706409Z","shell.execute_reply.started":"2024-04-18T09:05:25.663101Z","shell.execute_reply":"2024-04-18T09:05:25.705535Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"              id                    song_name  adults           artist  \\\n57          3347             My Private Movie       0         Westlife   \n186         6894                   Cinderella       0         Sweetbox   \n187         6895               For The Lonely       0         Sweetbox   \n188         6896                    Boyfriend       0         Sweetbox   \n189         6897             How Does It Feel       0         Sweetbox   \n...          ...                          ...     ...              ...   \n135480  36102766             Before I Met You       0            J.Fla   \n135592  36105794    Drown In You(Feat. Heezy)       0          Andy. J   \n135594  36106320  Wanderland (Feat. Shelhiel)       0            Blish   \n135649  36108763                    Neverland       0             eiji   \n135716  36108975               OPEN YOUR EYES       0  ONEMOREDAY, MUL   \n\n          album_id        date  genre  \\\n57            '80'  2001.02.13      3   \n186         '2024'  2001.04.01      3   \n187         '2024'  2001.04.01      3   \n188         '2024'  2001.04.01      3   \n189         '2024'  2001.04.01      3   \n...            ...         ...    ...   \n135480  '11164457'  2023.02.03      0   \n135592  '11165231'  2023.02.06      4   \n135594  '11165332'  2023.02.03      4   \n135649  '11165886'  2023.02.04      4   \n135716  '11165956'  2023.02.06      5   \n\n                                                   lyrics  has_kor  \n57      \\n\\n[Spoken]:\\n(yeah)(check it out)\\n[Shane] :...    False  \n186     Cinderella are you really that happy\\nCinderel...    False  \n187     This is for the lonely\\nThis is for the lonely...    False  \n188     Always hatin' on me\\nwhen you talk talk talk\\n...    False  \n189     Look at the me that silly girl\\nGave all I had...    False  \n...                                                   ...      ...  \n135480  Before I fell in love with you\\nI didn’t know ...    False  \n135592  Maybe I had a drink too much\\nBut I remember w...    False  \n135594  So what now \\nFace it, like it \\nI want to giv...    False  \n135649  How can I confess \\nyou look better in the sun...    False  \n135716  Open your eyes\\nOpen your eyes\\nI had to stay ...    False  \n\n[15004 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>song_name</th>\n      <th>adults</th>\n      <th>artist</th>\n      <th>album_id</th>\n      <th>date</th>\n      <th>genre</th>\n      <th>lyrics</th>\n      <th>has_kor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>57</th>\n      <td>3347</td>\n      <td>My Private Movie</td>\n      <td>0</td>\n      <td>Westlife</td>\n      <td>'80'</td>\n      <td>2001.02.13</td>\n      <td>3</td>\n      <td>\\n\\n[Spoken]:\\n(yeah)(check it out)\\n[Shane] :...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>6894</td>\n      <td>Cinderella</td>\n      <td>0</td>\n      <td>Sweetbox</td>\n      <td>'2024'</td>\n      <td>2001.04.01</td>\n      <td>3</td>\n      <td>Cinderella are you really that happy\\nCinderel...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>6895</td>\n      <td>For The Lonely</td>\n      <td>0</td>\n      <td>Sweetbox</td>\n      <td>'2024'</td>\n      <td>2001.04.01</td>\n      <td>3</td>\n      <td>This is for the lonely\\nThis is for the lonely...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>6896</td>\n      <td>Boyfriend</td>\n      <td>0</td>\n      <td>Sweetbox</td>\n      <td>'2024'</td>\n      <td>2001.04.01</td>\n      <td>3</td>\n      <td>Always hatin' on me\\nwhen you talk talk talk\\n...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>6897</td>\n      <td>How Does It Feel</td>\n      <td>0</td>\n      <td>Sweetbox</td>\n      <td>'2024'</td>\n      <td>2001.04.01</td>\n      <td>3</td>\n      <td>Look at the me that silly girl\\nGave all I had...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>135480</th>\n      <td>36102766</td>\n      <td>Before I Met You</td>\n      <td>0</td>\n      <td>J.Fla</td>\n      <td>'11164457'</td>\n      <td>2023.02.03</td>\n      <td>0</td>\n      <td>Before I fell in love with you\\nI didn’t know ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>135592</th>\n      <td>36105794</td>\n      <td>Drown In You(Feat. Heezy)</td>\n      <td>0</td>\n      <td>Andy. J</td>\n      <td>'11165231'</td>\n      <td>2023.02.06</td>\n      <td>4</td>\n      <td>Maybe I had a drink too much\\nBut I remember w...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>135594</th>\n      <td>36106320</td>\n      <td>Wanderland (Feat. Shelhiel)</td>\n      <td>0</td>\n      <td>Blish</td>\n      <td>'11165332'</td>\n      <td>2023.02.03</td>\n      <td>4</td>\n      <td>So what now \\nFace it, like it \\nI want to giv...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>135649</th>\n      <td>36108763</td>\n      <td>Neverland</td>\n      <td>0</td>\n      <td>eiji</td>\n      <td>'11165886'</td>\n      <td>2023.02.04</td>\n      <td>4</td>\n      <td>How can I confess \\nyou look better in the sun...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>135716</th>\n      <td>36108975</td>\n      <td>OPEN YOUR EYES</td>\n      <td>0</td>\n      <td>ONEMOREDAY, MUL</td>\n      <td>'11165956'</td>\n      <td>2023.02.06</td>\n      <td>5</td>\n      <td>Open your eyes\\nOpen your eyes\\nI had to stay ...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>15004 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df['genre']","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:05:29.331861Z","iopub.execute_input":"2024-04-18T09:05:29.332770Z","iopub.status.idle":"2024-04-18T09:05:29.340489Z","shell.execute_reply.started":"2024-04-18T09:05:29.332734Z","shell.execute_reply":"2024-04-18T09:05:29.339436Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0         0\n1         1\n2         0\n3         0\n5         0\n         ..\n135784    0\n135785    1\n135787    2\n135788    2\n135789    4\nName: genre, Length: 94743, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## dataset class 정의","metadata":{"id":"COZta4HWXb-8"}},{"cell_type":"code","source":"## dataset class를 정의합니다.\nclass SongDatasetTest(Dataset):\n    def __init__(self, df):\n        df = df.reset_index(drop=True)\n        self.song_names = df[\"song_name\"]\n        self.artists = df[\"artist\"]\n        self.lyrics = df[\"lyrics\"]\n        self.id = df[\"id\"]\n        self.has_kor = df[\"has_kor\"]\n\n    def __getitem__(self, idx):\n        song_name = self.song_names[idx]\n        artist = self.artists[idx]\n        lyrics = self.lyrics[idx]\n        id = self.id[idx]\n\n        return {'song_name': song_name,\n                'artist': artist,\n                'lyrics': lyrics,\n                'id': id}\n\n    def __len__(self):\n        return len(self.song_names)","metadata":{"id":"I_NjZ84f8mVO","execution":{"iopub.status.busy":"2024-04-18T09:05:32.537602Z","iopub.execute_input":"2024-04-18T09:05:32.537980Z","iopub.status.idle":"2024-04-18T09:05:32.545956Z","shell.execute_reply.started":"2024-04-18T09:05:32.537951Z","shell.execute_reply":"2024-04-18T09:05:32.544840Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"## test_dataset과 dataloader를 정의합니다.\ntest_datasets = SongDatasetTest(test_df)\n\n## Inference 시에는 shuffle=False로 설정해야 출력 순서가 바뀌지 않아 제대로 된 채점이 가능합니다.\n## 단, training 시에는 shuffle=True로 설정해주는 것이 좋습니다.\nBATCH_SIZE_TEST = 256\ntest_dataloader = DataLoader(test_datasets, batch_size = BATCH_SIZE_TEST, shuffle = False)\ntest_datasets[5515]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNawvpzW8sUR","outputId":"b6ec4791-ec32-4073-b805-0314135f6ee1","execution":{"iopub.status.busy":"2024-04-18T09:05:34.725717Z","iopub.execute_input":"2024-04-18T09:05:34.726067Z","iopub.status.idle":"2024-04-18T09:05:34.734572Z","shell.execute_reply.started":"2024-04-18T09:05:34.726037Z","shell.execute_reply":"2024-04-18T09:05:34.733444Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'song_name': 'Pray',\n 'artist': '더지타 (The GITA)',\n 'lyrics': '잠들 수도 없었던 아침에\\n머리 속은 기억 안에 있네\\n돌아가서 하나씩 떠올려\\n돌이킬 수 없다는 걸 알면서도\\nI pray\\nI pray\\nI pray\\nI pray\\n널 위해서 I pray\\n날 위해서 I pray\\n언제든지 I pray\\n잊지 말고 I pray\\n한 때는 나만을 생각했고\\n언제나 너만을 원망했어\\n그럴 때 넌 내 옆을 지켜줬고\\n그 순간 난 나만을 지켰었어\\n왜 그랬을까 하는 후회도\\n넌 어땠을까 하는 고민도\\n소용없겠지만\\nI pray\\nI pray\\nI pray\\nI pray\\n널 위해서 I pray\\n날 위해서 I pray\\n언제든지 I pray\\n잊지 말고 I pray\\n',\n 'id': 32595991}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"jxJ9vdDTXhqb"}},{"cell_type":"code","source":"!pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQev6Bjiqdl8","outputId":"b5b72f6a-164a-4180-c328-0eae3fe1388a","execution":{"iopub.status.busy":"2024-04-18T09:05:38.406052Z","iopub.execute_input":"2024-04-18T09:05:38.406422Z","iopub.status.idle":"2024-04-18T09:05:50.449571Z","shell.execute_reply.started":"2024-04-18T09:05:38.406392Z","shell.execute_reply":"2024-04-18T09:05:50.448350Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('using device: ', device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFHDZ19OInLy","outputId":"6fe4ad98-fba7-407c-8bc9-6fec1cd048b4","execution":{"iopub.status.busy":"2024-04-18T09:05:50.451983Z","iopub.execute_input":"2024-04-18T09:05:50.452871Z","iopub.status.idle":"2024-04-18T09:05:50.511850Z","shell.execute_reply.started":"2024-04-18T09:05:50.452831Z","shell.execute_reply":"2024-04-18T09:05:50.510715Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"using device:  cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, DistilBertTokenizerFast","metadata":{"id":"FwBOF-U_qtLU","execution":{"iopub.status.busy":"2024-04-18T09:05:50.513335Z","iopub.execute_input":"2024-04-18T09:05:50.513701Z","iopub.status.idle":"2024-04-18T09:05:59.669324Z","shell.execute_reply.started":"2024-04-18T09:05:50.513671Z","shell.execute_reply":"2024-04-18T09:05:59.668462Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"fzogWKAI2BWq","outputId":"d12145ee-c9b6-45cf-b61c-2aea5ef2c127","execution":{"iopub.status.busy":"2024-04-18T09:05:59.671353Z","iopub.execute_input":"2024-04-18T09:05:59.671712Z","iopub.status.idle":"2024-04-18T09:05:59.690576Z","shell.execute_reply.started":"2024-04-18T09:05:59.671679Z","shell.execute_reply":"2024-04-18T09:05:59.689509Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"              id                    song_name  adults           artist  \\\n0           2395                          긴 잠       0              INO   \n1           2396                     Alcatraz       0              INO   \n2           2397                           해요       0              INO   \n3           2398                       투비(鬪悲)       0              INO   \n5           2401                   니가 가르쳐준 것들       0              INO   \n...          ...                          ...     ...              ...   \n135784  36110233               바래 (feat. 신현우)       0              신지현   \n135785  36110235                           파도       0              백찬열   \n135787  36110996          파이팅 해야지 (Feat. 이영지)       0  부석순 (SEVENTEEN)   \n135788  36110997                        LUNCH       0  부석순 (SEVENTEEN)   \n135789  36110998  7시에 들어줘 (Feat. Peder Elias)       0  부석순 (SEVENTEEN)   \n\n          album_id        date  genre  \\\n0           '1869'  2001.03.16      0   \n1           '1869'  2001.03.16      1   \n2           '1869'  2001.03.16      0   \n3           '1869'  2001.03.16      0   \n5           '1869'  2001.03.16      0   \n...            ...         ...    ...   \n135784  '11166283'  2023.02.06      0   \n135785  '11166284'  2023.02.06      1   \n135787  '11166539'  2023.02.06      2   \n135788  '11166539'  2023.02.06      2   \n135789  '11166539'  2023.02.06      4   \n\n                                                   lyrics  has_kor  \n0       잠을 깨는 것이 싫었어\\n눈 뜨면 또 하루\\n니 곁을 살테니\\n오직 내꿈 속엔 넌 ...     True  \n1       이젠 널 가둬놓겠어\\n나의 품에\\n조금은 낯설겠지만\\n편해질꺼야\\n두려운 내 맘 때...     True  \n2       그녀와 나는요 그땐 참 어렸어요\\n많이 사랑했고 때론 많이 다퉜었죠\\n지금 생각하면...     True  \n3       예전처럼 다시 처음으로\\n서로 몰랐던 때로 돌아가\\n쉽진 않지만\\n부탁이야 잊어줘\\...     True  \n5       가끔 힘든 걸음으로 나\\n너를 찾아가\\n너의 품에 기대 울곤 했지\\n그때 너는 네게...     True  \n...                                                   ...      ...  \n135784  나를 만난 날들은 진심이었길 바래\\n누굴 만나 뭘 하든지 행복하길 바래\\n내 사진 ...     True  \n135785  환하던 세상엔 어두운 밤이 내려오고\\n반짝이던 해는 먹구름에 가려지고\\n푸르른 하늘...     True  \n135787  파이팅 해야지\\n파이팅\\n아뿔싸 일어나야지 아침인데\\n눈 감았다 뜨니 해가 중천인데...     True  \n135788  나는 지구 넌 어느 별 다른 우주 상관없어\\n같은 타임라인 속에 우리 평행하게 있다...     True  \n135789  알려줘 너의 오늘\\n찌뿌둥했던 아침부터\\n만원에 놓친 Bus\\nTaxi를 타야만 했...     True  \n\n[94743 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>song_name</th>\n      <th>adults</th>\n      <th>artist</th>\n      <th>album_id</th>\n      <th>date</th>\n      <th>genre</th>\n      <th>lyrics</th>\n      <th>has_kor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2395</td>\n      <td>긴 잠</td>\n      <td>0</td>\n      <td>INO</td>\n      <td>'1869'</td>\n      <td>2001.03.16</td>\n      <td>0</td>\n      <td>잠을 깨는 것이 싫었어\\n눈 뜨면 또 하루\\n니 곁을 살테니\\n오직 내꿈 속엔 넌 ...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2396</td>\n      <td>Alcatraz</td>\n      <td>0</td>\n      <td>INO</td>\n      <td>'1869'</td>\n      <td>2001.03.16</td>\n      <td>1</td>\n      <td>이젠 널 가둬놓겠어\\n나의 품에\\n조금은 낯설겠지만\\n편해질꺼야\\n두려운 내 맘 때...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2397</td>\n      <td>해요</td>\n      <td>0</td>\n      <td>INO</td>\n      <td>'1869'</td>\n      <td>2001.03.16</td>\n      <td>0</td>\n      <td>그녀와 나는요 그땐 참 어렸어요\\n많이 사랑했고 때론 많이 다퉜었죠\\n지금 생각하면...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2398</td>\n      <td>투비(鬪悲)</td>\n      <td>0</td>\n      <td>INO</td>\n      <td>'1869'</td>\n      <td>2001.03.16</td>\n      <td>0</td>\n      <td>예전처럼 다시 처음으로\\n서로 몰랐던 때로 돌아가\\n쉽진 않지만\\n부탁이야 잊어줘\\...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2401</td>\n      <td>니가 가르쳐준 것들</td>\n      <td>0</td>\n      <td>INO</td>\n      <td>'1869'</td>\n      <td>2001.03.16</td>\n      <td>0</td>\n      <td>가끔 힘든 걸음으로 나\\n너를 찾아가\\n너의 품에 기대 울곤 했지\\n그때 너는 네게...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>135784</th>\n      <td>36110233</td>\n      <td>바래 (feat. 신현우)</td>\n      <td>0</td>\n      <td>신지현</td>\n      <td>'11166283'</td>\n      <td>2023.02.06</td>\n      <td>0</td>\n      <td>나를 만난 날들은 진심이었길 바래\\n누굴 만나 뭘 하든지 행복하길 바래\\n내 사진 ...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>135785</th>\n      <td>36110235</td>\n      <td>파도</td>\n      <td>0</td>\n      <td>백찬열</td>\n      <td>'11166284'</td>\n      <td>2023.02.06</td>\n      <td>1</td>\n      <td>환하던 세상엔 어두운 밤이 내려오고\\n반짝이던 해는 먹구름에 가려지고\\n푸르른 하늘...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>135787</th>\n      <td>36110996</td>\n      <td>파이팅 해야지 (Feat. 이영지)</td>\n      <td>0</td>\n      <td>부석순 (SEVENTEEN)</td>\n      <td>'11166539'</td>\n      <td>2023.02.06</td>\n      <td>2</td>\n      <td>파이팅 해야지\\n파이팅\\n아뿔싸 일어나야지 아침인데\\n눈 감았다 뜨니 해가 중천인데...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>135788</th>\n      <td>36110997</td>\n      <td>LUNCH</td>\n      <td>0</td>\n      <td>부석순 (SEVENTEEN)</td>\n      <td>'11166539'</td>\n      <td>2023.02.06</td>\n      <td>2</td>\n      <td>나는 지구 넌 어느 별 다른 우주 상관없어\\n같은 타임라인 속에 우리 평행하게 있다...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>135789</th>\n      <td>36110998</td>\n      <td>7시에 들어줘 (Feat. Peder Elias)</td>\n      <td>0</td>\n      <td>부석순 (SEVENTEEN)</td>\n      <td>'11166539'</td>\n      <td>2023.02.06</td>\n      <td>4</td>\n      <td>알려줘 너의 오늘\\n찌뿌둥했던 아침부터\\n만원에 놓친 Bus\\nTaxi를 타야만 했...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>94743 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\nimport time\n","metadata":{"id":"nyLcjojjtvMC","execution":{"iopub.status.busy":"2024-04-18T09:06:05.101678Z","iopub.execute_input":"2024-04-18T09:06:05.102051Z","iopub.status.idle":"2024-04-18T09:06:05.106464Z","shell.execute_reply.started":"2024-04-18T09:06:05.102018Z","shell.execute_reply":"2024-04-18T09:06:05.105245Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# ver 2","metadata":{"id":"X7A--84DII0L"}},{"cell_type":"code","source":"## dataset class를 정의합니다.\nclass SongDatasetTest(Dataset):\n    def __init__(self, df):\n        df = df.reset_index(drop=True)\n        self.song_names = df[\"song_name\"]\n        self.artists = df[\"artist\"]\n        self.lyrics = df[\"lyrics\"]\n        self.id = df[\"id\"]\n        self.genre = df[\"genre\"]\n        self.korean = df['has_kor']\n\n    def __getitem__(self, idx):\n        song_name = self.song_names[idx]\n        artist = self.artists[idx]\n        lyrics = self.lyrics[idx]\n        id = self.id[idx]\n        label = self.genre[idx]\n        has_kor = 'Korean' if self.korean[idx] else 'English'\n        \n\n        return {'song_name': song_name,\n                'artist': artist,\n                'lyrics': lyrics,\n                'id': id,\n               'has_kor' : has_kor}, label\n\n    def __len__(self):\n        return len(self.song_names)","metadata":{"id":"NeW9qF3uIJ-6","execution":{"iopub.status.busy":"2024-04-18T09:20:51.426689Z","iopub.execute_input":"2024-04-18T09:20:51.427479Z","iopub.status.idle":"2024-04-18T09:20:51.435186Z","shell.execute_reply.started":"2024-04-18T09:20:51.427445Z","shell.execute_reply":"2024-04-18T09:20:51.434210Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train_df['genre'].unique","metadata":{"execution":{"iopub.status.busy":"2024-04-18T09:20:55.203028Z","iopub.execute_input":"2024-04-18T09:20:55.203401Z","iopub.status.idle":"2024-04-18T09:20:55.211509Z","shell.execute_reply.started":"2024-04-18T09:20:55.203372Z","shell.execute_reply":"2024-04-18T09:20:55.210507Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<bound method Series.unique of 0         0\n1         1\n2         0\n3         0\n5         0\n         ..\n135784    0\n135785    1\n135787    2\n135788    2\n135789    4\nName: genre, Length: 94743, dtype: int64>"},"metadata":{}}]},{"cell_type":"code","source":"## test_dataset과 dataloader를 정의합니다.\ntrain_datasets = SongDatasetTest(train_df)\n\n## Inference 시에는 shuffle=False로 설정해야 출력 순서가 바뀌지 않아 제대로 된 채점이 가능합니다.\n## 단, training 시에는 shuffle=True로 설정해주는 것이 좋습니다.\nBATCH_SIZE_TEST = 64\ntrain_dataloader = DataLoader(train_datasets, batch_size = BATCH_SIZE_TEST, shuffle = False)\ntrain_datasets[5515]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttPSYNXOIK8s","outputId":"fc3bed06-c836-45cf-932c-e87454c1aa7a","execution":{"iopub.status.busy":"2024-04-18T09:20:57.553838Z","iopub.execute_input":"2024-04-18T09:20:57.554255Z","iopub.status.idle":"2024-04-18T09:20:57.567944Z","shell.execute_reply.started":"2024-04-18T09:20:57.554223Z","shell.execute_reply":"2024-04-18T09:20:57.567015Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"({'song_name': 'Overlap',\n  'artist': '컨츄리 꼬꼬',\n  'lyrics': '오 그렇게 울지는 마\\n더는 미안하지 않아도 돼\\n돌아가고 싶던 널 그에게로\\n이제는 보낼께\\n둘이서라면 모든 걸\\n포기했던 너잖아\\n이대로는 너를 잡아둘 수 없는걸\\n늘 너의 눈빛은\\n나 아닌 그의 모습을\\n그리워만 하면서도\\n웃고 있는거야\\n더 오랜 시간을 참고 기다린대도\\n달라지지 않은 너를\\n이젠 떠날꺼야\\n나의 눈물\\n눈물 닦아 주려 하지 말아줘\\n오랜 시간\\n혼자 너의 손길 그릴테니\\n끝내 너를\\n너를 잊을수는 없을지 몰라\\n이젠 그에게 돌아가\\n남겨진 내 걱정은 하지마\\n\\n오 거짓말하지는 마\\n이젠 고민하지 않아도 돼\\n사랑하고 싶던 널\\n기억에서 이제는 지우려 해\\n널 위해서라면\\n죽음도 두렵지는 않지만\\n이대로는 너를 사랑할순 없는 걸\\n단 한 번이라도\\n너 아닌 다른 사람을\\n사랑한적 없는 난 혼자 남는거야\\n널 버리려 했던\\n그가 난 정말 싫지만\\n니가 행복하다면 그걸로 끝인 거야\\n내게 다시\\n다시 돌아오려 하지 말아줘\\n그와 함께\\n이별없는 사랑하게 될테니\\n이제 하루\\n하루 아파해야 할지도 몰라\\n제발 뒤돌아 보지마\\n달려가 널 잡을지도 몰라\\n나의 눈물\\n눈물 닦아 주려 하지 말아줘\\n오랜 시간\\n혼자 너의 손길 그릴테니\\n끝내 너를\\n너를 잊을 수는 없을지 몰라\\n이제 그에게 돌아가\\n남겨진 내 걱정은 하지마\\n달려가 널 잡을지도 몰라\\n \\n',\n  'id': 90067,\n  'has_kor': 'Korean'},\n 2)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, DistilBertTokenizerFast\ntokenizer = DistilBertTokenizerFast.from_pretrained('bert-base-multilingual-cased', do_lower_case=False) ## model used in training phase\nmodel = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=num_classes)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcQE9zbHIfip","outputId":"41a9af20-e0e1-4341-91be-17adea1ad989","execution":{"iopub.status.busy":"2024-04-18T09:06:20.436034Z","iopub.execute_input":"2024-04-18T09:06:20.436969Z","iopub.status.idle":"2024-04-18T09:06:29.297371Z","shell.execute_reply.started":"2024-04-18T09:06:20.436935Z","shell.execute_reply":"2024-04-18T09:06:29.296571Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfe008049b2a443c84d2ffff377315a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe30aa1b15842e29fb84ee52c8f315b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ae50693a7d4ccb9a68ffb398cc45cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"903c8fca33ed4227977eedf21edf17f4"}},"metadata":{}},{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'BertTokenizer'. \nThe class this function is called from is 'DistilBertTokenizerFast'.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73d015c97c3144cd9e0cbbc839593a38"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.optim as optim","metadata":{"id":"4Q0sWtpSJrUz","execution":{"iopub.status.busy":"2024-04-18T09:06:34.300093Z","iopub.execute_input":"2024-04-18T09:06:34.300886Z","iopub.status.idle":"2024-04-18T09:06:35.388669Z","shell.execute_reply.started":"2024-04-18T09:06:34.300853Z","shell.execute_reply":"2024-04-18T09:06:35.387609Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"result = []\n\noptimizer = optim.Adam(model.parameters(), lr=1e-5)\n\nitr = 1\np_itr = 50\nepochs = 3\ntotal_loss = 0\ntotal_len = 0\ntotal_correct = 0\n\nmodel.train()\nfor epoch in range(epochs):\n\n#  test_correct_predictions, test_incorrect_predictions, count = 0, 0, 1\n  for data, label in tqdm(train_dataloader):\n        optimizer.zero_grad()\n\n        lyrics = data['lyrics']\n        song_name = data['song_name']\n        artist = data['artist']\n        has_kor = data['has_kor']\n        \n        inputs = song_name + '[]' + has_kor\n        encoded_inputs = tokenizer(lyrics, return_tensors='pt', padding='max_length', truncation=True, max_length=100).to(device)\n\n        label = label.to(device)\n        model = model.to(device)\n\n        outputs = model(**encoded_inputs, labels=label)\n        loss = outputs.loss\n        logits = outputs.logits\n\n        pred = torch.argmax(F.softmax(logits), dim=1)\n        correct = pred.eq(label)\n        total_correct += correct.sum().item()\n        total_len += len(label)\n        total_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n\n        if itr % p_itr == 0:\n            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n            total_loss = 0\n            total_len = 0\n            total_correct = 0\n\n        itr+=1\n\n      # for i, output in enumerate(outputs):\n      #     song = data['song_name'][i]\n      #     artist = data['artist'][i]\n      #     predicted = torch.topk(output, 1).indices.item()\n      #     id = data['id'][i].item()\n\n\n      #     output_for_print = {\n      #       \"Song\": song,\n      #       \"Artist\": artist,\n      #       \"Predicted\": label2id[predicted],\n      #       \"Id\": str(id)\n      #     }\n\n      #     output_for_submission = {\n      #       \"id\": id,\n      #       \"genre\": predicted\n      #     }\n\n      #     result.append(output_for_submission)\n\n      #     print(f\"{count} / {len(test_datasets)}\")\n      #     count += 1\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":453},"id":"NIze8J9wIK52","outputId":"da523c49-7376-4e54-fd14-61f229459c4a","execution":{"iopub.status.busy":"2024-04-18T09:06:39.481591Z","iopub.execute_input":"2024-04-18T09:06:39.482225Z","iopub.status.idle":"2024-04-18T09:17:40.721505Z","shell.execute_reply.started":"2024-04-18T09:06:39.482193Z","shell.execute_reply":"2024-04-18T09:17:40.720194Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"  0%|          | 0/1481 [00:00<?, ?it/s]/tmp/ipykernel_32/3692004609.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  pred = torch.argmax(F.softmax(logits), dim=1)\n  3%|▎         | 50/1481 [00:50<24:38,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 50 -> Train Loss: 1.6046, Accuracy: 0.423\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 100/1481 [01:44<26:07,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 100 -> Train Loss: 1.4367, Accuracy: 0.453\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 150/1481 [02:42<25:02,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 150 -> Train Loss: 1.6454, Accuracy: 0.375\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▎        | 200/1481 [03:38<24:30,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 200 -> Train Loss: 1.5352, Accuracy: 0.463\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 250/1481 [04:35<23:19,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 250 -> Train Loss: 1.4584, Accuracy: 0.479\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 300/1481 [05:32<22:23,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 300 -> Train Loss: 1.4466, Accuracy: 0.462\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▎       | 350/1481 [06:29<21:29,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 350 -> Train Loss: 1.4949, Accuracy: 0.417\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 400/1481 [07:26<20:33,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 400 -> Train Loss: 1.3318, Accuracy: 0.519\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 450/1481 [08:23<19:38,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 450 -> Train Loss: 1.2640, Accuracy: 0.546\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 500/1481 [09:20<18:37,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 500 -> Train Loss: 1.1810, Accuracy: 0.587\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 550/1481 [10:17<17:38,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"[Epoch 1/3] Iteration 550 -> Train Loss: 1.2891, Accuracy: 0.529\n","output_type":"stream"},{"name":"stderr","text":" 40%|███▉      | 587/1481 [11:00<16:45,  1.13s/it]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m32\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m29 \u001b[0m\u001b[2m│     \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m\u001b[2m│     \u001b[0mpred = torch.argmax(F.softmax(logits), dim=\u001b[94m1\u001b[0m)                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m│     \u001b[0mcorrect = pred.eq(label)                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m32 \u001b[2m│     \u001b[0mtotal_correct += correct.sum().item()                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m\u001b[2m│     \u001b[0mtotal_len += \u001b[96mlen\u001b[0m(label)                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m│     \u001b[0mtotal_loss += loss.item()                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│     \u001b[0mloss.backward()                                                                       \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mKeyboardInterrupt\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">32</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>pred = torch.argmax(F.softmax(logits), dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>correct = pred.eq(label)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>32 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>total_correct += correct.sum().item()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>total_len += <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(label)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>total_loss += loss.item()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>loss.backward()                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model_base')","metadata":{"execution":{"iopub.status.busy":"2023-08-25T17:03:25.250449Z","iopub.execute_input":"2023-08-25T17:03:25.250807Z","iopub.status.idle":"2023-08-25T17:03:26.962021Z","shell.execute_reply.started":"2023-08-25T17:03:25.250772Z","shell.execute_reply":"2023-08-25T17:03:26.960706Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"class SongDatasetTest_2(Dataset):\n    def __init__(self, df):\n        df = df.reset_index(drop=True)\n        self.song_names = df[\"song_name\"]\n        self.artists = df[\"artist\"]\n        self.lyrics = df[\"lyrics\"]\n        self.id = df[\"id\"]\n\n    def __getitem__(self, idx):\n        song_name = self.song_names[idx]\n        artist = self.artists[idx]\n        lyrics = self.lyrics[idx]\n        id = self.id[idx]\n\n        return {'song_name': song_name,\n                'artist': artist,\n                'lyrics': lyrics,\n                'id': id}\n\n    def __len__(self):\n        return len(self.song_names)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T17:05:07.280768Z","iopub.execute_input":"2023-08-25T17:05:07.281142Z","iopub.status.idle":"2023-08-25T17:05:07.290889Z","shell.execute_reply.started":"2023-08-25T17:05:07.281109Z","shell.execute_reply":"2023-08-25T17:05:07.289869Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, DistilBertTokenizerFast\nMODEL_PATH = '/kaggle/working/model_base' ## model weight path\nMODEL_NAME = 'bert-base-multilingual-cased' ## model name\ntokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_NAME, do_lower_case=False) ## model used in training phase\ntest_model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_classes).to(device)  ## tokenizer used in training phase\n\n### 저장된 모델의 state_dict를 불러옵니다.\ndevice = \"cuda\"\ntest_model.load_state_dict(torch.load(MODEL_PATH))\ntest_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-08-25T17:05:08.939686Z","iopub.execute_input":"2023-08-25T17:05:08.940058Z","iopub.status.idle":"2023-08-25T17:05:11.852017Z","shell.execute_reply.started":"2023-08-25T17:05:08.940027Z","shell.execute_reply":"2023-08-25T17:05:11.851067Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'BertTokenizer'. \nThe class this function is called from is 'DistilBertTokenizerFast'.\nSome weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=7, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"label_convert = {0 : 0, 1 : 1, 2 : 2, 3 : 4, 4 : 5, 5 : 7, 6 : 16}","metadata":{"execution":{"iopub.status.busy":"2023-08-25T17:05:15.014024Z","iopub.execute_input":"2023-08-25T17:05:15.014431Z","iopub.status.idle":"2023-08-25T17:05:15.019439Z","shell.execute_reply.started":"2023-08-25T17:05:15.014393Z","shell.execute_reply":"2023-08-25T17:05:15.018388Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"result = []\nwith torch.no_grad():\n    test_correct_predictions, test_incorrect_predictions, count = 0, 0, 1\n    for data in tqdm(test_dataloader):\n        inputs = data['lyrics']\n        encoded_inputs = tokenizer(inputs, return_tensors='pt', padding='max_length', truncation=True, max_length=100).to(device)\n        test_model = test_model.to(device)\n\n        test_model.eval()\n        outputs = test_model(**encoded_inputs).logits\n        _, predicted = torch.max(outputs, 1)\n\n        for i, output in enumerate(outputs):\n            song = data['song_name'][i]\n            artist = data['artist'][i]\n            predicted = torch.topk(output, 1).indices.item()\n            \n            predicted = label_convert[predicted]\n            \n            id = data['id'][i].item()\n            \n            \n            output_for_print = {\n              \"Song\": song,\n              \"Artist\": artist,\n              \"Predicted\": label2id[predicted],\n              \"Id\": str(id)\n            }\n\n            output_for_submission = {\n              \"id\": id,\n              \"genre\": predicted\n            }\n\n            result.append(output_for_submission)\n\n            #print(f\"{count} / {len(test_datasets)}\")\n            count += 1\n            \n            ### 단순 결과 출력용입니다. 제거해도 괜찮습니다.\n            #pprint(output_for_print, sort_dicts=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-25T17:05:16.558830Z","iopub.execute_input":"2023-08-25T17:05:16.559616Z","iopub.status.idle":"2023-08-25T17:06:18.267419Z","shell.execute_reply.started":"2023-08-25T17:05:16.559578Z","shell.execute_reply":"2023-08-25T17:06:18.266400Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"100%|██████████| 42/42 [01:01<00:00,  1.47s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test = pd.DataFrame(result)\nRESULT_PATH = f'/kaggle/working/prediction_1.csv'\ndf_test.to_csv(RESULT_PATH, index=False)\ndf_test","metadata":{"id":"uCbjIcjpI34y","execution":{"iopub.status.busy":"2023-08-25T17:06:18.269259Z","iopub.execute_input":"2023-08-25T17:06:18.270226Z","iopub.status.idle":"2023-08-25T17:06:18.324893Z","shell.execute_reply.started":"2023-08-25T17:06:18.270187Z","shell.execute_reply":"2023-08-25T17:06:18.323939Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"             id  genre\n0      33093058      7\n1       2388517      4\n2      31013021     16\n3      34801938      0\n4       4061054      4\n...         ...    ...\n10495    897937      0\n10496  32362102      7\n10497    354645      4\n10498  33367298      5\n10499   5668960      0\n\n[10500 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33093058</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2388517</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31013021</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34801938</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4061054</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10495</th>\n      <td>897937</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10496</th>\n      <td>32362102</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>10497</th>\n      <td>354645</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10498</th>\n      <td>33367298</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10499</th>\n      <td>5668960</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10500 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}